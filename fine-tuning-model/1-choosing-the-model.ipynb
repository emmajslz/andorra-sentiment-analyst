{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a bit of research, the multilingual BERT -> [mBERT](https://huggingface.co/google-bert/bert-base-multilingual-cased) ([GitHub](https://github.com/google-research/bert/blob/master/multilingual.md)) seems like a logical first approach to the project.\n",
    "\n",
    "We will use mBERT and fine-tune it, training it with our own dataset and labels (sentiments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to gauge the citizen's opinion on a topic around which the outputted articles revolve around.\n",
    "\n",
    "That's why we'll perform sentiment analysis on is the **comments** in each article.\n",
    "\n",
    "This will give us insight into how the citizens feel about different topics treated in the press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, we'll want to pre-train mBERT with a corpus of catalan text, since this model is multilingual and we could give it some insight as to the nuances of the catalan language.\n",
    "\n",
    "2. Then, we'll have to lable our dataset with the pertinent sentiment labels. We'll need to:\n",
    "\n",
    "    - Choose the label set\n",
    "    - Label each comment\n",
    "\n",
    "    If the final dataset is fairly large, manually labeling each comment can be an arduous task.\n",
    "\n",
    "    That is why we will follow a semi-supervised learning approach, performing **pseudo-labeling**:\n",
    "\n",
    "    - We'll manually label a subset of the original dataset: 200-300 comments.\n",
    "    - We'll use mBERT to predict the labels for the unlabeled data.\n",
    "    - We will retain the most confident predictions (those with high probability scores), and then treat them as additional labeled data.\n",
    "    - Finally, we'll retrain the model based on both the original labeled data and the new pseudo-labeled data.\n",
    "\n",
    "3. Once we have a labeled dataset, we can use it to train mBERT.\n",
    "\n",
    "4. Model evaluation\n",
    "\n",
    "    We'll use basic evaluation metrics like accuracy and F1-score for each of the label classes.\n",
    "\n",
    "5. Finally, we can deploy the model to perform analysis on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a set of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the comments we'll manually label, we have to choose a set of labels to assign, that we later want our model to be able to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the model to be able to understand the context of each comment, seeing as if the comment is in response to somebody else, they may direct disagreement/agreement to the response, but that may not necessarily be the feeling towards the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having scraped many articles and having been a reader of the Andorran press for some years, I can anticipate the fact that most of these comments will have negative connotations. Normally people tend to leave comments to express disagreement or anger, especially for the topics we have chosen, which are generating a lot of debate among the people currently.\n",
    "\n",
    "That is why we want to have nuance in our labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach to labels is:\n",
    "\n",
    "- Positive\n",
    "- Neutral\n",
    "- Negative\n",
    "- Very Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/andorra-sentiment-analyst/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andorra-sentiment-analyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
